---
title: "Friends Project - R Code"
author: "Wenyang Cao, Wenling Zhou, Sixuan Li, Haoran Yang"
date: "2024-03-01"
output: 
  html_document: 
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55), tidy = TRUE)
```
## Code:
```{r}
# Load necessary libraries
library(rvest)
library(dplyr)
library(stringr)
library(purrr)

# Base URL for the main Friends transcript page
base_url <- "https://fangj.github.io/friends/"

# Function to scrape episode links from the main page
scrape_episode_links <- function(base_url) {
  main_page <- read_html(base_url)
  links <- main_page %>%
    html_nodes("a") %>%
    html_attr("href") %>%
    na.omit() %>%
    str_subset("^season/") %>%
    unique() %>%
    paste0(base_url, .)
  return(links)
}

# Function to scrape dialogues and additional details from an episode's transcript page
scrape_dialogues <- function(episode_link) {
  page <- read_html(episode_link)
  
  # Extract episode title
  episode_title <- page %>%
    html_nodes("title") %>%
    html_text() %>%
    str_trim()
  
  dialogues <- page %>%
    html_nodes("p") %>%
    html_text() %>%
    .[str_detect(., "^(Monica|Joey|Chandler|Phoebe|Ross|Rachel):")]
  
  if (length(dialogues) == 0) {
    return(data.frame(author = character(0), quote = character(0), quote_order = integer(0), episode_link = character(0), episode_number = character(0), episode_title = character(0), season = integer(0), episode = integer(0), stringsAsFactors = FALSE))
  }
  
  authors <- str_extract(dialogues, "^[A-Za-z]+")
  quotes <- str_replace_all(dialogues, "^[A-Za-z]+:", "") %>%
    str_trim()
  quote_order <- seq_along(quotes)
  
  # Correctly parsing season and episode from the URL
  matches <- str_match(episode_link, "season/(\\d{2})(\\d{2})\\.html")
  season <- as.numeric(matches[1,2])
  episode <- as.numeric(matches[1,3])
  episode_number <- sprintf("S%02dE%02d", season, episode)
  
  data.frame(
    author = authors,
    quote = quotes,
    quote_order = quote_order,
    episode_link = episode_link,
    episode_number = episode_number,
    episode_title = episode_title,
    season = season,
    episode = episode,
    stringsAsFactors = FALSE
  )
}

# Scrape episode links
episode_links <- scrape_episode_links(base_url)

# Scrape dialogues for each episode and compile into a single dataframe
all_dialogues <- map_df(episode_links, ~scrape_dialogues(.x))

# Check the structure and the first few rows of the compiled dialogues dataframe
#print(str(all_dialogues))
#head(all_dialogues)

# Code to write the dataframe to a CSV file
write.csv(all_dialogues, "friends_quotes.csv", row.names = FALSE)
```

### Session Info:
```{r}
sessionInfo()
```

